#抓取平台概要设计


|时间|撰写人|修订内容|备注|
|:-:|:---:|:-----:|:-:|
|2018.08.09|王家葳|建立文档|初稿|

## 需求

随着爬虫脚本的逐日增多，维护与管理的成本增加

抓取平台应运而生，承担调度、管理、维护的功能

## 抓取流程梗概

![抓取流程梗概][1]

## 系统组织结构:

- Scheduler: 调度器
- Crawler: 抓取器
- Parser: 解析器
- Persistence: 持久化

## 模块划分

- **调度模块**

![Scheduler][2]

- **抓取模块**

![Crawler][3]

- **解析模块/持久化模块**

![Parser&Persistence][4]

## 功能划分

- Scheduler: 调度器，承担解析项目，定时调度的功能

	- JobState:完成种子的构造、url去重、定时执行等
	- ResourceState:状态监测
	- logging:记录日志
	- middleware:任务分发
	
- Crawler: 抓取器，多个，承担接收种子，完成请求过程
	
	- SessionPool:session池，cookie管理
	- HttpApiPool:请求池,根据条件完成该次请求
	- ProxyPool:代理池，提供代理服务
	- UAPool:user-agent池，为爬虫提供不同的ua伪装各种身份
	- middleware:中间件，接收种子，发送新url
	- logging:日志模块
	 
- Parser& Persistence: 解析器，承担解析返回的HTML/JS并交给Persistence做持久化处理
	
	- API: 外部接口，调用项目中对应的解析及存储规则
	- middleware:中间件，发送新url
	- logging:日志模块
	

## 运行设计

scheduler读取projectList从而确定项目，生成种子放入队列，Crawler接收种子完成请求输出请求结果，然后由parse/persistence继续处理

## 数据结构设计

## 出错处理
[1]:https://github.com/beforeuwait/spider_platform/blob/master/%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/%E6%8A%93%E5%8F%96%E5%B9%B3%E5%8F%B0%E6%80%BB%E8%A7%88.jpg?raw=true
[2]:https://github.com/beforeuwait/spider_platform/blob/master/%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/Scheduler%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg?raw=true
[3]:https://github.com/beforeuwait/spider_platform/blob/master/%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/Crawler%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg?raw=true
[4]:https://github.com/beforeuwait/spider_platform/blob/master/%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9D%97.jpg?raw=true